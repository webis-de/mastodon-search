{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from mastodon import Mastodon\n",
    "from numpy import exp, log10\n",
    "from pandas import read_csv, concat\n",
    "from pathlib import Path\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "from fediverse_analysis.instance_data.analyze import Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Remove\n",
    "INSTANCES = ['fedi.halcyon-is.land', 'fedibird.com', 'meerjungfrauengrotte.de', 'mental.social', 'penguicon.social', 'toot.rebel.ar']\n",
    "# Input\n",
    "INSTANCE_DATA_PATH = Path('/mnt/ceph/storage/data-in-progress/data-teaching/theses/wstud-thesis-ernst/instance-data/mastodon.jsonl')\n",
    "SAMPLED_INSTANCES_PATH = Path('/mnt/ceph/storage/data-in-progress/data-teaching/theses/wstud-thesis-ernst/sample/instances.txt')\n",
    "REMOVED_INSTANCES_PATH = Path('/mnt/ceph/storage/data-in-progress/data-teaching/theses/wstud-thesis-ernst/sample/instances_removed_from_sample.json')\n",
    "# Output\n",
    "RESAMPLE_OUTPUT_FILE_NAME = 'instances_resampled'\n",
    "RESAMPLE_OUTPUT_FILE_EXT = 'txt'\n",
    "NEW_FULL_SAMPLE_OUTPUT_FILE_NAME = 'instances.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in input file: 22178\n",
      "Removed for (partially) no data: 11822\n",
      "Removed duplicates: 2\n",
      "Remaining: 10354\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "with open(INSTANCE_DATA_PATH, 'r') as file:\n",
    "    an = Analyzer(file)\n",
    "with open(REMOVED_INSTANCES_PATH, 'r') as file:\n",
    "    removed_instances = loads(file.readline())\n",
    "with open(SAMPLED_INSTANCES_PATH, 'r') as file:\n",
    "    sampled_instances = [instance.strip() for instance in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6120: RuntimeWarning: overflow encountered in divide\n",
      "  return np.sum((1 + np.log(shifted/scale)/shape**2)/shifted)\n",
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/scipy/stats/_continuous_distns.py:6111: RuntimeWarning: invalid value encountered in log\n",
      "  lndata = np.log(data - loc)\n"
     ]
    }
   ],
   "source": [
    "COLUMNS = ['total_users', 'monthly_users', 'total_statuses',\n",
    "        'mean_weekly_statuses', 'mean_weekly_logins', 'mean_weekly_registrations']\n",
    "\n",
    "cols_prob_measures = {\n",
    "    col: lognorm\n",
    "    for col in COLUMNS\n",
    "}\n",
    "df = an.df\n",
    "# Estimate probability distributions over activity columns\n",
    "distributions = {\n",
    "    col: dist.fit(df[col])\n",
    "    for col, dist in cols_prob_measures.items()\n",
    "}\n",
    "# Compute normalize activity score by dividing by the estimated probability.\n",
    "for col, dist in cols_prob_measures.items():\n",
    "    shape, location, scale = distributions[col]\n",
    "    df[f\"{col}_log_probability\"] = dist.logpdf(df[col], shape, location, scale)\n",
    "# Compute joint probability (under assumption of independence; using log probabilities for numerical stability)\n",
    "df[\"log_probability\"] = 0\n",
    "for col in cols_prob_measures.keys():\n",
    "    df[\"log_probability\"] += df[f\"{col}_log_probability\"]\n",
    "\n",
    "df.sort_values(\"log_probability\", inplace=True)\n",
    "df.drop(removed_instances, inplace=True)\n",
    "df[\"weight\"] = exp(-df[\"log_probability\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.loc[sampled_instances]\n",
    "to_resample = df.loc[INSTANCES]\n",
    "\n",
    "# Remove already sampled instances\n",
    "df.drop(sampled_instances, inplace=True)\n",
    "orig_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/tschaeggaer/Projekte/thesis-ernst/code/venv/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "new_instances = []\n",
    "\n",
    "# Resample\n",
    "for instance in to_resample.index:\n",
    "    new_instance = log10(df['weight'].div(to_resample.loc[instance]['weight'])).abs().sort_values().idxmin()\n",
    "    new_instances.append(new_instance)\n",
    "    df.drop(new_instance, inplace=True)\n",
    "\n",
    "resample = orig_df.loc[new_instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      mastodon.nycmesh.net\n",
       "1              nicaloro.com\n",
       "2              blogi.social\n",
       "3    mastodon.cesko.digital\n",
       "4              exito.social\n",
       "5              terra.social\n",
       "Name: instance, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_instance_sample = concat((sample.drop(INSTANCES), resample))\n",
    "new_instance_sample.reset_index()['instance'].to_csv(Path(NEW_FULL_SAMPLE_OUTPUT_FILE_NAME), index=False, header=False)\n",
    "# Full DataFrame. Maybe we want to have that data later.\n",
    "resample.to_csv(Path(RESAMPLE_OUTPUT_FILE_NAME + '_full_data.csv'))\n",
    "# Raw instance list only.\n",
    "resampled_instances = resample.reset_index()['instance']\n",
    "resampled_instances.to_csv(Path(RESAMPLE_OUTPUT_FILE_NAME + '.' + RESAMPLE_OUTPUT_FILE_EXT), index=False, header=False)\n",
    "resampled_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if instances are crawlable\n",
    "for instance in resampled_instances:\n",
    "    m = Mastodon(api_base_url=instance)\n",
    "    assert len(m.timeline(timeline='public')) > 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
